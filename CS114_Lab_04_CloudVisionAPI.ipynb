{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CS114.Lab-04.\bCloudVisionAPI.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ttvhh/CS114.K21/blob/master/CS114_Lab_04_%08CloudVisionAPI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t5jOCJ-oqEx4",
        "colab_type": "text"
      },
      "source": [
        "#CS114 - BÀI TẬP THỰC HÀNH LAB-04\n",
        "**@Lê Đình Duy**\n",
        "\n",
        "Đây là tài liệu hướng dẫn thực hành về phát triển ứng dụng sử dụng Google Cloud Vision API\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5_PomwEFzI2E",
        "colab_type": "text"
      },
      "source": [
        "#Làm quen với Google Cloud Platform (GCP) - Các bước chính\n",
        "\n",
        "*(SV tự tìm hiểu)*\n",
        "\n",
        "* \bTạo project từ Google Cloud Console http://console.cloud.google.com/ - đặt tên là CS114-CloudVisionAPI-Demo-MSSV\n",
        "* Kích hoạt Vision API (và AutoML API) https://console.cloud.google.com/apis/dashboard\n",
        "* Xem Dashboard của Vision API https://console.cloud.google.com/apis/api/vision.googleapis.com/\n",
        "* Tạo API Key https://console.cloud.google.com/apis/credentials \n",
        "* Tạo Service Account https://cloud.google.com/docs/authentication#service_accounts\n",
        "* Tham khảo tài liệu của Vision API https://cloud.google.com/vision/docs \n",
        "\n",
        "Tham khảo\n",
        "* https://cloud.google.com/vision/docs/setup\n",
        "\n",
        "**Hướng dẫn:**\n",
        "\n",
        "*Để sử dụng các dịch vụ của GCP, cần phải tạo project.*\n",
        "\n",
        "A project organizes all your GCP resources. A project consists of the following components:\n",
        "* a set of collaborators\n",
        "* enabled APIs (and other resources)\n",
        "* monitoring tools\n",
        "* **billing information - cần phải có credit card**\n",
        "* authentication and access controls\n",
        "\n",
        "**You have \bTHREE OPTIONS for calling the Vision API:**\n",
        "\n",
        "* Google supported client libraries (recommended) - Python https://googleapis.dev/python/vision/latest/index.html\n",
        "* REST https://cloud.google.com/vision/docs/reference/rest\n",
        "* gRPC https://cloud.google.com/vision/docs/reference/rpc\n",
        "\n",
        "The client libraries are available for several popular languages. For information on installing the client libraries, see Vision API Client Libraries.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M4l2ANgkhoL_",
        "colab_type": "text"
      },
      "source": [
        "# Sử dụng Command Line (curl) với API_KEY\n",
        "\n",
        "Trong phần này, chúng ta sẽ thử tính năng Image Annotation của Goolge Vision API. Để có thể sử dụng được API, cần phải có API_KEY và hiểu cách gọi tương ứng qua REST API\n",
        "\n",
        "Tham khảo\n",
        "* https://cloud.google.com/vision/docs/quickstart-cli\n",
        "* https://becominghuman.ai/how-to-use-google-cloud-vision-api-4fbd800641f9"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CasdaV8ltaj8",
        "colab_type": "text"
      },
      "source": [
        "**Ảnh input**\n",
        "\n",
        "![\bShanghai](https://cloud.google.com/vision/docs/images/shanghai_small.jpeg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hVhI76ZOpuCf",
        "colab_type": "text"
      },
      "source": [
        "**Create the request JSON**\n",
        "\n",
        "*Create the JSON request file with the following text, and save it as a `request.json` plain text file in your working directory:*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RHOVjN7spxFI",
        "colab_type": "text"
      },
      "source": [
        "```\n",
        "{\n",
        "  \"requests\": [\n",
        "    {\n",
        "      \"image\": {\n",
        "        \"source\": {\n",
        "          \"imageUri\": \"gs://cloud-samples-data/vision/using_curl/shanghai.jpeg\"\n",
        "        }\n",
        "      },\n",
        "      \"features\": [\n",
        "        {\n",
        "          \"type\": \"LABEL_DETECTION\",\n",
        "          \"maxResults\": 3\n",
        "        },\n",
        "        {\n",
        "          \"type\": \"OBJECT_LOCALIZATION\",\n",
        "          \"maxResults\": 1\n",
        "        },\n",
        "        {\n",
        "          \"type\": \"TEXT_DETECTION\",\n",
        "          \"maxResults\": 1,\n",
        "          \"model\": \"builtin/latest\"\n",
        "        }\n",
        "      ]\n",
        "    }\n",
        "  ]\n",
        "}\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w83t5xsZqzQf",
        "colab_type": "text"
      },
      "source": [
        "**Send the request**\n",
        "\n",
        "*You use curl and the body content from request.json to send the request to the Vision API*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PrNchL2qcvfx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import getpass\n",
        "\n",
        "YOUR_API_KEY = getpass.getpass('Enter your API_KEY')\n",
        "\n",
        "!curl -v -s -H \"Content-Type: application/json\" \\\n",
        "    https://vision.googleapis.com/v1/images:annotate?key=$YOUR_API_KEY \\\n",
        "    --data-binary @request.json"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3nDrMdB3rjEI",
        "colab_type": "text"
      },
      "source": [
        "**Interpret the response**\n",
        "\n",
        "*You should see a JSON response similar to the one below*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "meLcDq5gr1tH",
        "colab_type": "text"
      },
      "source": [
        "```\n",
        "{\n",
        "  \"responses\": [\n",
        "    {\n",
        "      \"labelAnnotations\": [\n",
        "        {\n",
        "          \"mid\": \"/m/09g5pq\",\n",
        "          \"description\": \"People\",\n",
        "          \"score\": 0.9504782,\n",
        "          \"topicality\": 0.9504782\n",
        "        },\n",
        "        {\n",
        "          \"mid\": \"/m/01c8br\",\n",
        "          \"description\": \"Street\",\n",
        "          \"score\": 0.8911568,\n",
        "          \"topicality\": 0.8911568\n",
        "        },\n",
        "        {\n",
        "          \"mid\": \"/m/079bkr\",\n",
        "          \"description\": \"Mode of transport\",\n",
        "          \"score\": 0.89089024,\n",
        "          \"topicality\": 0.89089024\n",
        "        }\n",
        "      ],\n",
        "      \"textAnnotations\": [\n",
        "        {\n",
        "          \"locale\": \"zh\",\n",
        "          \"description\": \"牛牛面馆\\n\",\n",
        "          \"boundingPoly\": {\n",
        "            \"vertices\": [\n",
        "              {\n",
        "                \"x\": 159,\n",
        "                \"y\": 212\n",
        "              },\n",
        "              {\n",
        "                \"x\": 947,\n",
        "                \"y\": 212\n",
        "              },\n",
        "              {\n",
        "                \"x\": 947,\n",
        "                \"y\": 354\n",
        "              },\n",
        "              {\n",
        "                \"x\": 159,\n",
        "                \"y\": 354\n",
        "              }\n",
        "            ]\n",
        "          }\n",
        "        },\n",
        "        ...\n",
        "      ],\n",
        "      \"fullTextAnnotation\": {\n",
        "        \"pages\": [\n",
        "          {\n",
        "            ...\n",
        "                \"paragraphs\": [\n",
        "                  {\n",
        "                    ...\n",
        "                    \"words\": [\n",
        "                      {\n",
        "                        ...\n",
        "                        \"symbols\": [\n",
        "                          {\n",
        "                            ...\n",
        "                ],\n",
        "                \"blockType\": \"TEXT\"\n",
        "              }\n",
        "            ]\n",
        "          }\n",
        "        ],\n",
        "        \"text\": \"牛牛面馆\\n\"\n",
        "      },\n",
        "      \"localizedObjectAnnotations\": [\n",
        "        {\n",
        "          \"mid\": \"/m/01g317\",\n",
        "          \"name\": \"Person\",\n",
        "          \"score\": 0.94413143,\n",
        "          \"boundingPoly\": {\n",
        "            \"normalizedVertices\": [\n",
        "              {\n",
        "                \"x\": 0.26063988,\n",
        "                \"y\": 0.46869153\n",
        "              },\n",
        "              {\n",
        "                \"x\": 0.40736017,\n",
        "                \"y\": 0.46869153\n",
        "              },\n",
        "              {\n",
        "                \"x\": 0.40736017,\n",
        "                \"y\": 0.8957791\n",
        "              },\n",
        "              {\n",
        "                \"x\": 0.26063988,\n",
        "                \"y\": 0.8957791\n",
        "              }\n",
        "            ]\n",
        "          }\n",
        "        }\n",
        "      ]\n",
        "    }\n",
        "  ]\n",
        "}\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "caX87qW1tud7",
        "colab_type": "text"
      },
      "source": [
        "**Kết quả - Label Detection**\n",
        "\n",
        "![Label detection result](https://cloud.google.com/vision/docs/images/shanghai_labels.png)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y8gSSr2WuKWS",
        "colab_type": "text"
      },
      "source": [
        "**Kết quả - Object Detection**\n",
        "\n",
        "![Object detection result](https://cloud.google.com/vision/docs/images/shanghai_object.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yyhT82NJqS3X",
        "colab_type": "text"
      },
      "source": [
        "#Ứng dụng phát hiện khuôn mặt (face detection)\n",
        "\n",
        "*For your convenience, the Vision API can perform feature detection directly on an image file located in Google Cloud Storage or on the Web without the need to send the contents of the image file in the body of your request.*\n",
        "\n",
        "Tham khảo:\n",
        "* http://temp.theadora.io/google-cloud-python/vision/gapic/api.html\n",
        "* https://www.geeksforgeeks.org/how-to-use-vision-api-from-google-cloud/\n",
        "* https://google-cloud-python.readthedocs.io/en/0.32.0/vision/gapic/v1/types.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EfjbVuG2ulOg",
        "colab_type": "text"
      },
      "source": [
        "## Authentication với Service Account"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HSL8fOUebWxI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "\n",
        "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = os.path.join(os.curdir, 'creds.json') \n",
        "\n",
        "!echo $GOOGLE_APPLICATION_CREDENTIALS\n",
        "\n",
        "!cat $GOOGLE_APPLICATION_CREDENTIALS"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qr2Un8X_z1i3",
        "colab_type": "text"
      },
      "source": [
        "## Install Client Library"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bkiETLMRz4qU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install --upgrade google-cloud-vision"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YqlaBvjjqz0k",
        "colab_type": "text"
      },
      "source": [
        "## Hiển thị ảnh"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_3qbDr_55iI_",
        "colab_type": "text"
      },
      "source": [
        "*Viết lại thành hàm và nhập liệu từ form*\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zePqABatsuQk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab.patches import cv2_imshow\n",
        "import cv2\n",
        "import os\n",
        "\n",
        "def download_view(img_url):\n",
        "  img_file = os.path.basename(img_url)\n",
        "  !curl -o $img_file $img_url\n",
        "  img = cv2.imread(img_file, cv2.IMREAD_UNCHANGED)\n",
        "  cv2_imshow(img)\n",
        "  return img_file"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kSK8w8IrrmKg",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "#@title Nhập URL\n",
        "\n",
        "img_url = \"https://i-vnexpress.vnecdn.net/2020/03/25/my-1-jpeg-2570-1585098851.jpg\" #@param {type:\"string\"}\n",
        "\n",
        "print(img_url)\n",
        "img_file = download_view(img_url)\n",
        "print(img_file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SKKccgOV8PT5",
        "colab_type": "text"
      },
      "source": [
        "## Cài đặt hàm detect_face"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "guqisL214J6_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# https://cloud.google.com/vision/docs/face-tutorial\n",
        "\n",
        "def detect_face(face_file, max_results=20):\n",
        "    \"\"\"Uses the Vision API to detect faces in the given file.\n",
        "\n",
        "    Args:\n",
        "        face_file: A file-like object containing an image with faces.\n",
        "\n",
        "    Returns:\n",
        "        An array of Face objects with information about the picture.\n",
        "    \"\"\"\n",
        "    client = vision.ImageAnnotatorClient()\n",
        "\n",
        "    content = face_file.read()\n",
        "    image = types.Image(content=content)\n",
        "\n",
        "    return client.face_detection(\n",
        "        image=image, max_results=max_results).face_annotations"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C0jJ7JET8a5c",
        "colab_type": "text"
      },
      "source": [
        "## Cài đặt hàm highlight_faces"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vb4SURqP2e8-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# https://cloud.google.com/vision/docs/face-tutorial\n",
        "\n",
        "def highlight_faces(image, faces, output_filename):\n",
        "    \"\"\"Draws a polygon around the faces, then saves to output_filename.\n",
        "\n",
        "    Args:\n",
        "      image: a file containing the image with the faces.\n",
        "      faces: a list of faces found in the file. This should be in the format\n",
        "          returned by the Vision API.\n",
        "      output_filename: the name of the image file to be created, where the\n",
        "          faces have polygons drawn around them.\n",
        "    \"\"\"\n",
        "    im = Image.open(image)\n",
        "    draw = ImageDraw.Draw(im)\n",
        "    # Sepecify the font-family and the font-size\n",
        "    for face in faces:\n",
        "        box = [(vertex.x, vertex.y)\n",
        "               for vertex in face.bounding_poly.vertices]\n",
        "        draw.line(box + [box[0]], width=5, fill='#00ff00')\n",
        "        # Place the confidence value/score of the detected faces above the\n",
        "        # detection box in the output image\n",
        "        draw.text(((face.bounding_poly.vertices)[0].x,\n",
        "                   (face.bounding_poly.vertices)[0].y - 30),\n",
        "                  str(format(face.detection_confidence, '.3f')) + '%',\n",
        "                  fill='#FF0000')\n",
        "    im.save(output_filename)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aUtCuooD8hkF",
        "colab_type": "text"
      },
      "source": [
        "## Tổng hợp lại\n",
        "\n",
        "Lưu ý: \n",
        "* Paste link đến tập tin ảnh cần detect faces ở form trên\n",
        "* Kết quả sẽ hiển thị trong ảnh xxx.facedet.jpg"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "owhss3Mz4dbH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.cloud import vision\n",
        "from google.cloud.vision import types\n",
        "from PIL import Image, ImageDraw\n",
        "from google.colab.patches import cv2_imshow\n",
        "import cv2\n",
        "\n",
        "output_filename = img_file + '.facedet.jpg'\n",
        "max_results = 10\n",
        "\n",
        "with open(img_file, 'rb') as image:\n",
        "    faces = detect_face(image, max_results)\n",
        "    print('Found {} face{}'.format(\n",
        "        len(faces), '' if len(faces) == 1 else 's'))\n",
        "\n",
        "    print('Writing to file {}'.format(output_filename))\n",
        "    # Reset the file pointer, so we can read the file again\n",
        "    image.seek(0)\n",
        "    highlight_faces(image, faces, output_filename)\n",
        "    img = cv2.imread(output_filename, cv2.IMREAD_UNCHANGED)\n",
        "    cv2_imshow(img)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0x5nsJqB4Caq",
        "colab_type": "text"
      },
      "source": [
        "## Minh hoạ Face detection từ URI"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lo1MWh-NFWPg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# https://cloud.google.com/vision/docs/detecting-faces\n",
        "\n",
        "from google.cloud import vision\n",
        "\n",
        "def detect_faces_uri(uri):\n",
        "    \"\"\"Detects faces in the file located in Google Cloud Storage or the web.\"\"\"\n",
        "    client = vision.ImageAnnotatorClient()\n",
        "    image = vision.types.Image()\n",
        "    image.source.image_uri = uri\n",
        "\n",
        "    response = client.face_detection(image=image)\n",
        "    faces = response.face_annotations\n",
        "\n",
        "    # Names of likelihood from google.cloud.vision.enums\n",
        "    likelihood_name = ('UNKNOWN', 'VERY_UNLIKELY', 'UNLIKELY', 'POSSIBLE',\n",
        "                       'LIKELY', 'VERY_LIKELY')\n",
        "    print('Faces:')\n",
        "\n",
        "    for face in faces:\n",
        "        print('anger: {}'.format(likelihood_name[face.anger_likelihood]))\n",
        "        print('joy: {}'.format(likelihood_name[face.joy_likelihood]))\n",
        "        print('surprise: {}'.format(likelihood_name[face.surprise_likelihood]))\n",
        "\n",
        "        vertices = (['({},{})'.format(vertex.x, vertex.y)\n",
        "                    for vertex in face.bounding_poly.vertices])\n",
        "\n",
        "        print('face bounds: {}'.format(','.join(vertices)))\n",
        "\n",
        "    if response.error.message:\n",
        "        raise Exception(\n",
        "            '{}\\nFor more info on error messages, check: '\n",
        "            'https://cloud.google.com/apis/design/errors'.format(\n",
        "                response.error.message))\n",
        "     "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pMhu4xH9w6ta",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "detect_faces_uri(img_url)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}