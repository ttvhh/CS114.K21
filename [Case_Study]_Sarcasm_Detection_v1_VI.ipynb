{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "[Case_Study]_Sarcasm_Detection_v1_VI.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMnpSKLvk7UDMTyifhlqAMb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ttvhh/CS114.K21/blob/master/%5BCase_Study%5D_Sarcasm_Detection_v1_VI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fDlaKII6d_CL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "ce1786a1-4791-4164-bcf1-9e3868a18daa"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "77ydW5TOeRhl",
        "colab_type": "text"
      },
      "source": [
        "# **MÔ TẢ BÀI TOÁN**\n",
        "\n",
        "Con người có bản năng xã hội, tức là chúng ta tương tác với nhau theo những cách tích cực, thân thiện, và bản năng này còn mang một ý nghĩa chính là thao túng, điều khiển, châm chọc bất kì ai đó theo một cách tiêu cực.\n",
        "\n",
        "***Mỉa mai*** (*sarcasm*) vừa mang một khía cạnh hài hước tích cực mà cũng mang theo đó là những sự khó chịu tiêu cực. Vì vậy mà ***mỉa mai*** đóng một vai trò quan trọng trong tương tác xã hội của người. \n",
        "\n",
        "Tuy nhiên, đôi khi rất khó để có thể phát hiện được ai đó đang trêu chọc chúng ta với những lời lẽ mỉa mai hay không. Do đó, ở đây chúng ta sẽ xây dụng một mô hình có thể giúp chúng ta phát hiện những câu nói, lời văn mang tính mỉa mai."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LbiAmlsSgceB",
        "colab_type": "text"
      },
      "source": [
        "## **CÁC BƯỚC XÂY DỰNG MÔ HÌNH DỰ ĐOÁN**\n",
        "\n",
        "\n",
        "1.   Thu thập dữ liệu\n",
        "2.   Xử lý dữ liệu\n",
        "3.   Lựa chọn model\n",
        "4.   Học và fine-tuning\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vlPFJZ2Tg0X-",
        "colab_type": "text"
      },
      "source": [
        "###1. THU THẬP DỮ LIỆU\n",
        "\n",
        "Dựa vào yêu cầu bài toán đặt ra, trước hết ta có được bộ News Headlines Dataset từ trang chuyên về ML/DL như Kaggle, và mục tiêu của chúng ta chính là dự đoán xem một lời văn có mang tính mỉa mai hay không.\n",
        "\n",
        "Bộ dataset này được thu thập từ hai trang web khác nhau, trong đó lần lượt ***The Onion*** tập trung chủ yếu đăng tin mỉa mai, châm biếm và ***HuffPost*** đăng những bài báo có độ tin cậy, chính xác cao.\n",
        "\n",
        "Ta có thể lấy bộ dataset này ở đường link phía dưới:\n",
        "> [News Headlines Dataset For Sarcasm Detection](https://www.kaggle.com/rmisra/news-headlines-dataset-for-sarcasm-detection/kernels)\n",
        "\n",
        "**Mô tả dataset**\n",
        "\n",
        "*   ```article_link``` (type: Object): chứa những đường link dẫn tới trang tin tức tương ứng.\n",
        "\n",
        "*   ```headline``` (type: Object): chứa tiêu đề của những trang tin tức tương ứng.\n",
        "\n",
        "*   ```is_sarcastic``` (type: int64): chứa 0 (không mỉa mai) và 1 (mỉa mai).\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UMYhuie2mTtz",
        "colab_type": "text"
      },
      "source": [
        "Để có thể thu thập 2000 dữ liệu từ hai trang trên mà không sử dụng bộ dataset có sẵn thì ta phải xây dựng một ***web crawler*** chịu trách nhiệm tự động thu thập đường dẫn, tiêu đề và đánh nhãn 0 (đối với trang ***The Onion***) và 1 (đối với trang ***HuffPost***)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nvBtxpzmmArO",
        "colab_type": "text"
      },
      "source": [
        "Trước khi thu thập dữ liệu, ta cần cài đặt và import một số thư viện liên quan"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7HxaSTmpmLep",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "outputId": "9e355389-40f9-41ed-b482-4f3d01359c21"
      },
      "source": [
        "!pip install pandas requests bs4"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (1.0.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (2.23.0)\n",
            "Requirement already satisfied: bs4 in /usr/local/lib/python3.6/dist-packages (0.0.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from pandas) (1.18.5)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas) (2.8.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests) (2.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests) (2020.4.5.2)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.6/dist-packages (from bs4) (4.6.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.6.1->pandas) (1.12.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qAzS8PGKkeHa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import bs4\n",
        "import pandas\n",
        "import requests\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ogIo_U0im1YW",
        "colab_type": "text"
      },
      "source": [
        "####1.1. Scrape dữ liệu\n",
        "Sau đó, ta sử dụng hàm ```request.get``` để lấy dữ liệu từ trang TheOnion về. Thư viện requests sẽ tạo ra 1 yêu cầu GET cho máy chủ web để tải xuống nội dung HTML của trang web ta đang cần."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oh_Cd0SlnosG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "url = 'https://www.theonion.com/latest'\n",
        "def get_page_content(url):\n",
        "   page = requests.get(url,headers={\"Accept-Language\":\"en-US\"})\n",
        "   return bs4.BeautifulSoup(page.text,\"html.parser\")\n",
        "soup = get_page_content(url)\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-pjb0qPAnpwM",
        "colab_type": "text"
      },
      "source": [
        "####1.2. Trích xuất dữ liệu thô\n",
        "\n",
        "Ở mục này, ta sẽ lần lượt trích xuất từng dữ liệu thô của trang như: title, đường link tương ứng, url cho trang kế tiếp\n",
        "\n",
        "Việc chúng ta muốn lấy trường dữ liệu nào trong số dữ liệu đã được crawl về thì ta chỉ cần click chuột phải vào trang web, chọn ***Inspect element***. Sau đó tìm đến thuộc tính tương ứng.\n",
        "\n",
        "Code cell bên dưới tạo 2 mảng (titles, article_links) nhằm mục đích lưu trữ từng trường dữ liệu khác nhau. Từ đây, sẽ thực hiện lần lượt từng bước để trích xuất dữ liệu rồi lưu vào mảng kể trên."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DxpzW9tmnFAy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "titles = []\n",
        "article_link = []\n",
        "count = 0\n",
        "while(count < 1500):\n",
        "  soup = get_page_content(url)\n",
        "  #Lấy đường title cho mỗi bài báo\n",
        "  articles = soup.findAll('h2', class_=\"sc-759qgu-0 cYlVdn cw4lnv-6 eXwNRE\")\n",
        "\n",
        "  titles += [str(article.text) for article in articles]\n",
        "\n",
        "  # Lấy đường link tương ứng cho mỗi article\n",
        "  articles = soup.find_all('a', class_=\"sc-1out364-0 hMndXN js_link\")\n",
        "\n",
        "  for article in articles:\n",
        "    h2_element = article.find('h2', class_=\"sc-759qgu-0 cYlVdn cw4lnv-6 eXwNRE\")\n",
        "    if h2_element:\n",
        "      article_link.append(article['href'])\n",
        "  # Lấy đường url cho page tiếp theo\n",
        "  for article in articles:\n",
        "    if article.find('button'):\n",
        "      url = 'https://politics.theonion.com/' + article['href']\n",
        "\n",
        "  count = len(titles)\n",
        "\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ysCsoOrTnuJs",
        "colab_type": "text"
      },
      "source": [
        "####1.3. Trình bày dữ liệu với Pandas\n",
        "\n",
        "Bước này ta bắt đầu gán nhãn 1 cho toàn bộ dữ liệu thu thập được do ta vừa crawl dữ liệu về từ trang ***TheOnion***\n",
        "\n",
        "Tiếp theo đó, để biểu diễn dữ liệu một cách trực quan ta chỉ cần sử dụng ```pandas.DataFrame()```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X-tlG7Q9ntZS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "4e943a17-3165-4a26-c320-79f261ccc33a"
      },
      "source": [
        "is_sarcastic = [ 1 for _ in range(len(titles))]\n",
        "my_dataset = pandas.DataFrame({'is_sarcastic': is_sarcastic,\n",
        "    'titles':titles, \n",
        "    'article_link': article_link})\n",
        "\n",
        "pandas.DataFrame({'titles':titles,\n",
        "                  'article_link':article_link,\n",
        "                  'is_sarcastic':is_sarcastic})"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>titles</th>\n",
              "      <th>article_link</th>\n",
              "      <th>is_sarcastic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Researchers Predict Pandemic Could Result In 5...</td>\n",
              "      <td>https://www.theonion.com/researchers-predict-p...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Nancy Pelosi Calls Jamaal Bowman To Scold Him ...</td>\n",
              "      <td>https://politics.theonion.com/nancy-pelosi-cal...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Gamers, We Just Spent 4 Days Trapped In A Roll...</td>\n",
              "      <td>https://ogn.theonion.com/gamers-we-just-spent-...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>New Ultra-Reinforced Confederate Statue Includ...</td>\n",
              "      <td>https://www.theonion.com/new-ultra-reinforced-...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Defiant Florida Officials Announce They Will I...</td>\n",
              "      <td>https://www.theonion.com/defiant-florida-offic...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1499</th>\n",
              "      <td>Clinton Blasts Obama For Slamming Edwards Jab</td>\n",
              "      <td>https://politics.theonion.com/clinton-blasts-o...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1500</th>\n",
              "      <td>Bin Laden Called 'Virtually Impotent'</td>\n",
              "      <td>https://politics.theonion.com/bin-laden-called...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1501</th>\n",
              "      <td>Heartbroken Bush Runs After Departing Rove's Car</td>\n",
              "      <td>https://politics.theonion.com/heartbroken-bush...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1502</th>\n",
              "      <td>Senator Craig Arrested</td>\n",
              "      <td>https://politics.theonion.com/senator-craig-ar...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1503</th>\n",
              "      <td>Motor City Madman Attacks Dems</td>\n",
              "      <td>https://politics.theonion.com/motor-city-madma...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1504 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 titles  ... is_sarcastic\n",
              "0     Researchers Predict Pandemic Could Result In 5...  ...            1\n",
              "1     Nancy Pelosi Calls Jamaal Bowman To Scold Him ...  ...            1\n",
              "2     Gamers, We Just Spent 4 Days Trapped In A Roll...  ...            1\n",
              "3     New Ultra-Reinforced Confederate Statue Includ...  ...            1\n",
              "4     Defiant Florida Officials Announce They Will I...  ...            1\n",
              "...                                                 ...  ...          ...\n",
              "1499      Clinton Blasts Obama For Slamming Edwards Jab  ...            1\n",
              "1500              Bin Laden Called 'Virtually Impotent'  ...            1\n",
              "1501   Heartbroken Bush Runs After Departing Rove's Car  ...            1\n",
              "1502                             Senator Craig Arrested  ...            1\n",
              "1503                     Motor City Madman Attacks Dems  ...            1\n",
              "\n",
              "[1504 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kWtseusQnGKj",
        "colab_type": "text"
      },
      "source": [
        "####1.4. Export dữ liệu\n",
        "\n",
        "Sau khi hoàn thành xử lý dữ liệu, ta cần export ra một file .csv riêng."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ek5dIKy7nGga",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "my_dataset.to_csv(\"onion_titles.csv\")"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CccNttV3q_11",
        "colab_type": "text"
      },
      "source": [
        "####1.5. Gộp dữ liệu\n",
        "\n",
        "Thực hiện tương tự với trang ***HuffPost***:\n",
        "[The HuffPost Web Crawler](https://colab.research.google.com/drive/1UajgvAIteWdaGKwpjJATa87OxACeJeNE?usp=sharing&fbclid=IwAR2hwLsAYnrtxIQXNjiDAjQXGgE1_CiaT9wGrt9BGcVWKlhLWhe9O_q3Sb8#scrollTo=x29oW97W2Clh)\n",
        "\n",
        "Tới bước này, ta cần gộp dữ liệu từ hai trang trên thành 1 file .csv duy nhất để phục vụ cho việc test performance của model. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g9ewGedlrYJH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}